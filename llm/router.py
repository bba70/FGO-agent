import yaml
import os
from typing import List, Dict, Any, Union, AsyncGenerator, Optional

# å¯¼å…¥ä½ æ‰€æœ‰çš„é€‚é…å™¨å’ŒåŸºç±»
from llm.adapter.base import BaseAdapter
from llm.adapter.qwen import QwenAdapter
from llm.adapter.ollama import OllamaAdapter
from llm.adapter.vllm import VLLMAdapter
from llm.monitor import monitor_llm_call


class StreamWithMetadata:
    """
    åŒ…è£…å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œæ”¯æŒåœ¨æµå¼ä¼ è¾“è¿‡ç¨‹ä¸­åŠ¨æ€è®¾ç½®å’Œè·å–å…ƒæ•°æ®
    """
    def __init__(self, generator: AsyncGenerator, instance_name: str = None, physical_model_name: str = None):
        self._generator = generator
        self.instance_name: Optional[str] = instance_name
        self.physical_model_name: Optional[str] = physical_model_name
        self._chunks = []  # æ”¶é›†æ‰€æœ‰chunksç”¨äºtokenè®¡æ•°
        self.failover_events: List[Dict[str, Any]] = []  # å®¹ç¾äº‹ä»¶è®°å½•
        
    def __aiter__(self):
        return self
        
    async def __anext__(self):
        chunk = await self._generator.__anext__()
        self._chunks.append(chunk)
        return chunk
    
    def set_metadata(self, instance_name: str, physical_model_name: str):
        """è®¾ç½®å…ƒæ•°æ®"""
        self.instance_name = instance_name
        self.physical_model_name = physical_model_name
    
    def get_metadata(self) -> tuple[Optional[str], Optional[str]]:
        """è·å–å…ƒæ•°æ®"""
        return self.instance_name, self.physical_model_name
    
    def get_chunks(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å·²æ¥æ”¶çš„chunks"""
        return self._chunks
    
    def add_failover_event(self, event: Dict[str, Any]):
        """æ·»åŠ å®¹ç¾äº‹ä»¶"""
        self.failover_events.append(event)
    
    def get_failover_events(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å®¹ç¾äº‹ä»¶"""
        return self.failover_events

class ModelRouter:
    """
    æ¨¡å‹è·¯ç”±å™¨,æ˜¯æ¨¡å‹ä¸­å°çš„æ ¸å¿ƒã€‚
    è´Ÿè´£åŠ è½½é…ç½®ã€ç®¡ç†é€‚é…å™¨å®ä¾‹ï¼Œå¹¶æ ¹æ®ç­–ç•¥æ‰§è¡Œæ¨¡å‹è°ƒç”¨ã€‚
    """
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        åˆå§‹åŒ–è·¯ç”±å™¨ï¼ŒåŠ è½½é…ç½®å¹¶åˆ›å»ºé€‚é…å™¨å®ä¾‹ã€‚
        """
        self._load_config(config_path)
        self._create_adapters()

    def _load_config(self, config_path: str):
        """åŠ è½½å¹¶è§£æ YAML é…ç½®æ–‡ä»¶ã€‚"""
        print("ğŸ”§ æ­£åœ¨åŠ è½½æ¨¡å‹ä¸­å°é…ç½®...")
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        self.models = {model['name']: model for model in self.config['models']}
        self.instances = {inst['name']: inst for inst in self.config['model_instances']}
        print("é…ç½®åŠ è½½æˆåŠŸ!")

    def _create_adapters(self):
        """æ ¹æ®é…ç½®ï¼Œåˆ›å»ºæ‰€æœ‰éœ€è¦çš„é€‚é…å™¨å®ä¾‹å¹¶ç¼“å­˜ã€‚"""
        self.adapters: Dict[str, BaseAdapter] = {}
        
        # é€‚é…å™¨ç±»å‹åˆ°ç±»çš„æ˜ å°„
        ADAPTER_MAP = {
            "qwen": QwenAdapter,
            "ollama": OllamaAdapter,
            "vllm": VLLMAdapter
        }

        for name, config in self.instances.items():
            adapter_class = ADAPTER_MAP.get(config['type'])
            if adapter_class:
                init_kwargs = {
                    key: os.path.expandvars(value.replace("env(", "${").replace(")", "}")) if isinstance(value, str) and value.startswith("env(") else value
                    for key, value in config.items() if key != 'type' and key != 'name'
                }
                try:
                    self.adapters[name] = adapter_class(**init_kwargs)
                    print(f"é€‚é…å™¨ '{name}' ({config['type']}) å·²åˆ›å»ºã€‚")
                except Exception as e:
                    print(f"åˆ›å»ºé€‚é…å™¨ '{name}' å¤±è´¥: {e}")
            else:
                print(f"æœªçŸ¥çš„é€‚é…å™¨ç±»å‹ '{config['type']}' for instance '{name}'")
        print("æ‰€æœ‰é€‚é…å™¨åˆ›å»ºå®Œæ¯•!")

    @monitor_llm_call(type="chat")
    async def chat(
        self,
        messages: List[Dict[str, str]],
        model: str, # è¿™æ˜¯é€»è¾‘æ¨¡å‹åï¼Œå¦‚ "fgo-chat-model"
        stream: bool = False,
        **kwargs: Any
    ) -> Union[tuple[Dict[str, Any], str, str, List[Dict[str, Any]]], StreamWithMetadata]:
        """
        æ‰§è¡ŒèŠå¤©è¯·æ±‚çš„ç»Ÿä¸€å…¥å£ã€‚
        
        Returns:
            éæµå¼: (result, instance_name, physical_model_name, failover_events)
            æµå¼: StreamWithMetadata å¯¹è±¡ï¼ˆåŒ…å«å…ƒæ•°æ®å’Œå®¹ç¾äº‹ä»¶ï¼‰
        """
        model_config = self.models.get(model)
        if not model_config:
            raise ValueError(f"æœªçŸ¥çš„é€»è¾‘æ¨¡å‹: '{model}'")
            
        instance_names = model_config['instances']
        
        last_exception = None

        if not stream:
            # éæµå¼åœºæ™¯ï¼šè®°å½•å®¹ç¾äº‹ä»¶
            failover_events = []
            
            for instance_name in instance_names:
                adapter = self.adapters.get(instance_name)
                physical_model_name = model_config['instance_model_names'][instance_name]
                
                if not adapter:
                    print(f"æ‰¾ä¸åˆ°å®ä¾‹ '{instance_name}' çš„é€‚é…å™¨ï¼Œè·³è¿‡ã€‚")
                    failover_events.append({
                        "instance_name": instance_name,
                        "status": "skipped",
                        "reason": "é€‚é…å™¨æœªæ‰¾åˆ°"
                    })
                    continue
                
                try:
                    print(f"[éæµå¼] æ­£åœ¨å°è¯•å®ä¾‹ '{instance_name}'...")
                    result = await adapter.chat(messages, physical_model_name, stream, **kwargs)
                    
                    # æˆåŠŸï¼Œè®°å½•æˆåŠŸäº‹ä»¶
                    failover_events.append({
                        "instance_name": instance_name,
                        "physical_model_name": physical_model_name,
                        "status": "success"
                    })
                    
                    # è¿”å›ç»“æœå’Œå®¹ç¾äº‹ä»¶
                    return result, instance_name, physical_model_name, failover_events
                    
                except Exception as e:
                    print(f"å®ä¾‹ '{instance_name}' è°ƒç”¨å¤±è´¥: {e}")
                    failover_events.append({
                        "instance_name": instance_name,
                        "physical_model_name": physical_model_name,
                        "status": "failed",
                        "error": str(e)
                    })
                    last_exception = e      

            raise Exception(f"æ‰€æœ‰å®ä¾‹å‡è°ƒç”¨å¤±è´¥ã€‚æœ€åä¸€æ¬¡é”™è¯¯: {last_exception}") from last_exception
        else:
            # æµå¼åœºæ™¯ï¼šä½¿ç”¨é—­åŒ…æ•è·å…ƒæ•°æ®å’Œå®¹ç¾äº‹ä»¶
            metadata = {'instance_name': None, 'physical_model_name': None}
            failover_events = []
            
            async def stream_failover_generator():
                """å†…éƒ¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œå®ç°æ•…éšœè½¬ç§»é€»è¾‘"""
                last_exception = None
                
                for instance_name in instance_names:
                    adapter = self.adapters.get(instance_name)
                    physical_model_name = model_config['instance_model_names'][instance_name]
                    
                    if not adapter:
                        print(f"æ‰¾ä¸åˆ°å®ä¾‹ '{instance_name}' çš„é€‚é…å™¨ï¼Œè·³è¿‡ã€‚")
                        failover_events.append({
                            "instance_name": instance_name,
                            "status": "skipped",
                            "reason": "é€‚é…å™¨æœªæ‰¾åˆ°"
                        })
                        continue
                    
                    try:
                        print(f"[æµå¼] æ­£åœ¨å°è¯•å®ä¾‹ '{instance_name}'...")
                        
                        adapter_stream_generator = await adapter.chat(
                            messages, physical_model_name, stream=True, **kwargs
                        )

                        # æˆåŠŸè·å–ç”Ÿæˆå™¨åï¼Œè®¾ç½®å…ƒæ•°æ®åˆ°é—­åŒ…å˜é‡
                        metadata['instance_name'] = instance_name
                        metadata['physical_model_name'] = physical_model_name
                        
                        # è®°å½•æˆåŠŸäº‹ä»¶
                        failover_events.append({
                            "instance_name": instance_name,
                            "physical_model_name": physical_model_name,
                            "status": "success"
                        })
                        
                        async for chunk in adapter_stream_generator:
                            yield chunk
                        
                        print(f"[æµå¼] å®ä¾‹ '{instance_name}' ä¼ è¾“å®Œæˆã€‚")
                        return 
                        
                    except Exception as e:
                        print(f"[æµå¼] å®ä¾‹ '{instance_name}' è°ƒç”¨å¤±è´¥: {e}")
                        failover_events.append({
                            "instance_name": instance_name,
                            "physical_model_name": physical_model_name,
                            "status": "failed",
                            "error": str(e)
                        })
                        last_exception = e
                
                raise Exception(f"æ‰€æœ‰æµå¼å®ä¾‹å‡è°ƒç”¨å¤±è´¥ã€‚æœ€åä¸€æ¬¡é”™è¯¯: {last_exception}") from last_exception

            # åˆ›å»ºåŒ…è£…å¯¹è±¡ï¼Œä¼ å…¥ç”Ÿæˆå™¨
            stream_wrapper = StreamWithMetadata(stream_failover_generator())
            # ä¿å­˜å…ƒæ•°æ®å­—å…¸å’Œå®¹ç¾äº‹ä»¶åˆ—è¡¨çš„å¼•ç”¨
            stream_wrapper._metadata_dict = metadata
            stream_wrapper._failover_events_list = failover_events
            return stream_wrapper


    async def embed(
        self,
        texts: List[str],
        model: str, # è¿™æ˜¯é€»è¾‘æ¨¡å‹åï¼Œå¦‚ "fgo-emded-model"
        **kwargs: Any
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–‡æœ¬åµŒå…¥è¯·æ±‚çš„ç»Ÿä¸€å…¥å£ã€‚
        """
        model_config = self.models.get(model)
        if not model_config:
            raise ValueError(f"æœªçŸ¥çš„é€»è¾‘æ¨¡å‹: '{model}'")
            
        instance_names = model_config['instances']
        
        last_exception = None
        

        try:
            for instance_name in instance_names:
                adapter = self.adapters.get(instance_name)
                physical_model_name = model_config['instance_model_names'].get(instance_name)
                
                if not adapter:
                    print(f"æ‰¾ä¸åˆ°å®ä¾‹ '{instance_name}' çš„é€‚é…å™¨ï¼Œè·³è¿‡ã€‚")
                    continue
                if not physical_model_name:
                    print(f"æœªåœ¨é…ç½®ä¸­ä¸ºå®ä¾‹ '{instance_name}' æ‰¾åˆ° 'instance_model_names'ï¼Œè·³è¿‡ã€‚")
                    continue
                
                try:
                    print(f"æ­£åœ¨å°è¯•ä½¿ç”¨å®ä¾‹ '{instance_name}' (æ¨¡å‹: {physical_model_name}) è¿›è¡ŒåµŒå…¥...")
                    # è°ƒç”¨é€‚é…å™¨çš„ embed æ–¹æ³•
                    return await adapter.embed(texts, physical_model_name, **kwargs)
                except Exception as e:
                    print(f"å®ä¾‹ '{instance_name}' åµŒå…¥è°ƒç”¨å¤±è´¥: {e}")
                    last_exception = e
                    # ç»§ç»­å¾ªç¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¤‡ç”¨å®ä¾‹
                    
            # å¦‚æœæ‰€æœ‰å®ä¾‹éƒ½å¤±è´¥äº†
        except:
            raise Exception(f"æ‰€æœ‰å®ä¾‹å‡åµŒå…¥è°ƒç”¨å¤±è´¥ã€‚æœ€åä¸€æ¬¡é”™è¯¯: {last_exception}") from last_exception
