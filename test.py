# from llm.router import ModelRouter
# import asyncio


# async def test_stream():
#     """æµ‹è¯•æµå¼è¾“å‡º"""
#     print("=" * 50)
#     print("æµ‹è¯•æµå¼è¾“å‡º")
#     print("=" * 50)
    
#     router = ModelRouter(config_path="llm/config.yaml")
#     stream_result = await router.chat(
#         model="fgo-chat-model",
#         messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹è‡ªå·±"}],
#         stream=True,
#     )
    
#     # stream_result ç°åœ¨æ˜¯ StreamWithMetadata å¯¹è±¡
#     print("æµå¼è¾“å‡ºï¼š", end="")
#     async for chunk in stream_result:
#         content = chunk.get("choices", [{}])[0].get("delta", {}).get("content")
#         if content:
#             print(content, end="", flush=True)
    
#     print("\n")
#     # æµå¼ä¼ è¾“å®Œæˆåï¼Œå¯ä»¥è·å–å…ƒæ•°æ®ï¼ˆé€šè¿‡é—­åŒ…å˜é‡ï¼‰
#     if hasattr(stream_result, '_metadata_dict'):
#         instance_name = stream_result._metadata_dict.get('instance_name')
#         physical_model_name = stream_result._metadata_dict.get('physical_model_name')
#         print(f"ä½¿ç”¨çš„å®ä¾‹: {instance_name}")
#         print(f"ç‰©ç†æ¨¡å‹: {physical_model_name}")


# async def test_non_stream():
#     """æµ‹è¯•éæµå¼è¾“å‡º"""
#     print("\n" + "=" * 50)
#     print("æµ‹è¯•éæµå¼è¾“å‡º")
#     print("=" * 50)
    
#     router = ModelRouter(config_path="llm/config.yaml")
#     result, instance_name, physical_model_name, failover_events = await router.chat(
#         model="fgo-chat-model",
#         messages=[{"role": "user", "content": "ä½ å¥½"}],
#         stream=False,
#     )
    
#     # æ‰“å°ç»“æœ
#     content = result.get("choices", [{}])[0].get("message", {}).get("content")
#     print(f"å›å¤: {content}")
#     print(f"ä½¿ç”¨çš„å®ä¾‹: {instance_name}")
#     print(f"ç‰©ç†æ¨¡å‹: {physical_model_name}")
#     print(f"Token ä½¿ç”¨: {result.get('usage', {})}")
#     print(f"å®¹ç¾äº‹ä»¶: {failover_events}")


# async def main():
#     """ä¸»æµ‹è¯•å‡½æ•°"""
#     # æµ‹è¯•æµå¼
#     await test_stream()
    
#     # æµ‹è¯•éæµå¼
#     await test_non_stream()


# if __name__ == "__main__":
#     asyncio.run(main())



# """
# æµ‹è¯• parse.py çš„è¾“å‡ºç»“æ„
# """


# import json
# from data.parse_wiki import parse_full_wikitext

# # è¯»å–ä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶
# with open('data/textarea/é˜¿å°”æ‰˜è‰é›…Â·æ½˜å¾·æ‹‰è´¡.txt', 'r', encoding='utf-8') as f:
#     wikitext_content = f.read()

# # è§£æ
# parsed_data = parse_full_wikitext(wikitext_content)

# # æ‰“å°JSONç»“æ„
# print(json.dumps(parsed_data, indent=2, ensure_ascii=False))

# # æ‰“å°ç»“æ„æ¦‚è§ˆ
# print("\n" + "="*80)
# print("æ•°æ®ç»“æ„æ¦‚è§ˆï¼š")
# print("="*80)
# for key, value in parsed_data.items():
#     if isinstance(value, dict):
#         print(f"\nã€{key}ã€‘ (å­—å…¸)")
#         for k, v in list(value.items())[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
#             print(f"  {k}: {str(v)[:50]}...")
#     elif isinstance(value, list):
#         print(f"\nã€{key}ã€‘ (åˆ—è¡¨, é•¿åº¦: {len(value)})")
#         if value:
#             print(f"  ç¬¬ä¸€é¡¹ç±»å‹: {type(value[0])}")
#             if isinstance(value[0], dict):
#                 print(f"  ç¬¬ä¸€é¡¹çš„é”®: {list(value[0].keys())}")
#     else:
#         print(f"\nã€{key}ã€‘: {str(value)[:50]}")


from src.tools.rag.build_vectorstore import build_vectorstore

build_vectorstore()

# """
# RAG æ£€ç´¢å’Œé‡æ’åºåŠŸèƒ½æµ‹è¯•
# """
# import sys
# import logging
# from pathlib import Path

# # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
# project_root = Path(__file__).parent.parent.parent.parent
# sys.path.insert(0, str(project_root))

# from src.tools.rag.rag import (
#     RAGRetriever,
#     retrieve_documents,
#     calculate_retrieval_quality
# )

# # é…ç½®æ—¥å¿—
# logging.basicConfig(
#     level=logging.INFO,
#     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
# )
# logger = logging.getLogger(__name__)


# def test_vectordb_connection():
#     """æµ‹è¯• 1: å‘é‡æ•°æ®åº“è¿æ¥"""
#     print("\n" + "="*60)
#     print("æµ‹è¯• 1: å‘é‡æ•°æ®åº“è¿æ¥")
#     print("="*60)
    
#     try:
#         retriever = RAGRetriever()
#         collection = retriever.vectordb.get_collection("fgo_servants")
#         count = collection.count()
#         print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æˆåŠŸ")
#         print(f"ğŸ“Š é›†åˆåç§°: fgo_servants")
#         print(f"ğŸ“Š æ–‡æ¡£æ•°é‡: {count}")
#         return True
#     except Exception as e:
#         print(f"âŒ å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
#         return False


# def test_basic_retrieval():
#     """æµ‹è¯• 2: åŸºæœ¬æ£€ç´¢ï¼ˆä¸é‡æ’åºï¼‰"""
#     print("\n" + "="*60)
#     print("æµ‹è¯• 2: åŸºæœ¬æ£€ç´¢ï¼ˆä¸é‡æ’åºï¼‰")
#     print("="*60)
    
#     test_queries = [
#         "ç›ä¿®çš„å®å…·æ˜¯ä»€ä¹ˆ",
#         "é˜¿å°”æ‰˜è‰é›…çš„æŠ€èƒ½",
#         "å‰å°”ä¼½ç¾ä»€çš„èµ„æ–™",
#     ]
    
#     try:
#         retriever = RAGRetriever(top_k=3)
        
#         for query in test_queries:
#             print(f"\nğŸ” æŸ¥è¯¢: {query}")
#             docs = retriever.retrieve(query=query, top_k=3)
            
#             if docs:
#                 print(f"âœ… æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
#                 for i, doc in enumerate(docs, 1):
#                     print(f"  [{i}] ç›¸ä¼¼åº¦: {doc['score']:.3f}")
#                     print(f"      ä»è€…: {doc['metadata'].get('servant_name', 'N/A')}")
#                     print(f"      ç±»å‹: {doc['metadata'].get('chunk_type', 'N/A')}")
#                     print(f"      å†…å®¹: {doc['content'][:80]}...")
#             else:
#                 print(f"âš ï¸ æœªæ£€ç´¢åˆ°æ–‡æ¡£")
        
#         return True
#     except Exception as e:
#         print(f"âŒ åŸºæœ¬æ£€ç´¢æµ‹è¯•å¤±è´¥: {str(e)}")
#         import traceback
#         traceback.print_exc()
#         return False


# def test_crossencoder_rerank():
#     """æµ‹è¯• 3: CrossEncoder é‡æ’åº"""
#     print("\n" + "="*60)
#     print("æµ‹è¯• 3: CrossEncoder é‡æ’åº")
#     print("="*60)
    
#     query = "ç›ä¿®çš„å®å…·æ•ˆæœæ˜¯ä»€ä¹ˆ"
    
#     try:
#         retriever = RAGRetriever(
#             top_k=5,
#             rerank_model_name="BAAI/bge-reranker-base"
#         )
        
#         print(f"ğŸ” æŸ¥è¯¢: {query}")
        
#         # æ£€ç´¢å¹¶é‡æ’åº
#         docs = retriever.retrieve_and_rerank(
#             query=query,
#             top_k=5,
#             rerank_method="crossencoder"
#         )
        
#         if docs:
#             print(f"âœ… é‡æ’åºå®Œæˆï¼Œå…± {len(docs)} ä¸ªæ–‡æ¡£")
#             print(f"\n{'æ’å':<6} {'åŸå§‹åˆ†æ•°':<10} {'CEåˆ†æ•°':<10} {'é‡æ’åˆ†æ•°':<10} {'ä»è€…':<15} {'ç±»å‹'}")
#             print("-" * 80)
            
#             for i, doc in enumerate(docs, 1):
#                 print(
#                     f"{i:<6} "
#                     f"{doc['score']:<10.3f} "
#                     f"{doc.get('ce_score', 0):<10.3f} "
#                     f"{doc.get('rerank_score', 0):<10.3f} "
#                     f"{doc['metadata'].get('servant_name', 'N/A'):<15} "
#                     f"{doc['metadata'].get('chunk_type', 'N/A')}"
#                 )
#                 print(f"       å†…å®¹: {doc['content'][:100]}...")
#                 print()
#         else:
#             print(f"âš ï¸ æœªæ£€ç´¢åˆ°æ–‡æ¡£")
#             return False
        
#         return True
#     except Exception as e:
#         print(f"âŒ CrossEncoder é‡æ’åºæµ‹è¯•å¤±è´¥: {str(e)}")
#         import traceback
#         traceback.print_exc()
#         return False


# def test_keyword_rerank():
#     """æµ‹è¯• 4: å…³é”®è¯é‡æ’åºï¼ˆfallbackï¼‰"""
#     print("\n" + "="*60)
#     print("æµ‹è¯• 4: å…³é”®è¯é‡æ’åºï¼ˆfallbackï¼‰")
#     print("="*60)
    
#     query = "ç›ä¿®çš„é˜²å¾¡æŠ€èƒ½"
    
#     try:
#         retriever = RAGRetriever(top_k=5)
        
#         print(f"ğŸ” æŸ¥è¯¢: {query}")
        
#         # ä½¿ç”¨å…³é”®è¯é‡æ’åº
#         docs = retriever.retrieve_and_rerank(
#             query=query,
#             top_k=5,
#             rerank_method="keyword"
#         )
        
#         if docs:
#             print(f"âœ… å…³é”®è¯é‡æ’åºå®Œæˆï¼Œå…± {len(docs)} ä¸ªæ–‡æ¡£")
#             print(f"\n{'æ’å':<6} {'åŸå§‹åˆ†æ•°':<10} {'é‡æ’åˆ†æ•°':<10} {'ä»è€…':<15} {'ç±»å‹'}")
#             print("-" * 70)
            
#             for i, doc in enumerate(docs, 1):
#                 print(
#                     f"{i:<6} "
#                     f"{doc['score']:<10.3f} "
#                     f"{doc.get('rerank_score', 0):<10.3f} "
#                     f"{doc['metadata'].get('servant_name', 'N/A'):<15} "
#                     f"{doc['metadata'].get('chunk_type', 'N/A')}"
#                 )
#         else:
#             print(f"âš ï¸ æœªæ£€ç´¢åˆ°æ–‡æ¡£")
#             return False
        
#         return True
#     except Exception as e:
#         print(f"âŒ å…³é”®è¯é‡æ’åºæµ‹è¯•å¤±è´¥: {str(e)}")
#         import traceback
#         traceback.print_exc()
#         return False


# def test_retrieval_quality():
#     """æµ‹è¯• 5: æ£€ç´¢è´¨é‡è¯„ä¼°"""
#     print("\n" + "="*60)
#     print("æµ‹è¯• 5: æ£€ç´¢è´¨é‡è¯„ä¼°")
#     print("="*60)
    
#     test_queries = [
#         ("ç›ä¿®çš„å®å…·æ˜¯ä»€ä¹ˆ", "é«˜è´¨é‡æŸ¥è¯¢"),
#         ("ä»è€…", "ä½è´¨é‡æŸ¥è¯¢ï¼ˆå¤ªå®½æ³›ï¼‰"),
#         ("é˜¿å°”æ‰˜è‰é›…Â·æ½˜å¾·æ‹‰è´¡çš„èª“çº¦èƒœåˆ©ä¹‹å‰‘", "é«˜è´¨é‡æŸ¥è¯¢ï¼ˆå…·ä½“ï¼‰"),
#     ]
    
#     try:
#         for query, description in test_queries:
#             print(f"\nğŸ” æŸ¥è¯¢: {query} ({description})")
            
#             docs = retrieve_documents(
#                 query=query,
#                 top_k=5,
#                 rerank=True,
#                 rerank_method="crossencoder"
#             )
            
#             quality = calculate_retrieval_quality(docs)
            
#             if quality > 0.7:
#                 level = "é«˜è´¨é‡ âœ…"
#             elif quality > 0.5:
#                 level = "ä¸­ç­‰è´¨é‡ âš ï¸"
#             else:
#                 level = "ä½è´¨é‡ âŒ"
            
#             print(f"   è´¨é‡åˆ†æ•°: {quality:.3f} ({level})")
#             print(f"   æ–‡æ¡£æ•°é‡: {len(docs)}")
#             if docs:
#                 print(f"   Topæ–‡æ¡£åˆ†æ•°: {docs[0].get('rerank_score', 0):.3f}")
        
#         return True
#     except Exception as e:
#         print(f"âŒ è´¨é‡è¯„ä¼°æµ‹è¯•å¤±è´¥: {str(e)}")
#         import traceback
#         traceback.print_exc()
#         return False


# def test_compare_rerank_methods():
#     """æµ‹è¯• 6: å¯¹æ¯”ä¸åŒé‡æ’åºæ–¹æ³•"""
#     print("\n" + "="*60)
#     print("æµ‹è¯• 6: å¯¹æ¯”ä¸åŒé‡æ’åºæ–¹æ³•")
#     print("="*60)
    
#     query = "ç›ä¿®çš„å®å…·"
#     methods = ["score", "keyword", "crossencoder"]
    
#     try:
#         retriever = RAGRetriever(top_k=5)
        
#         print(f"ğŸ” æŸ¥è¯¢: {query}\n")
        
#         results = {}
#         for method in methods:
#             print(f"ğŸ“Š æ–¹æ³•: {method}")
#             docs = retriever.retrieve_and_rerank(
#                 query=query,
#                 top_k=5,
#                 rerank_method=method
#             )
#             results[method] = docs
            
#             if docs:
#                 quality = calculate_retrieval_quality(docs)
#                 print(f"   è´¨é‡åˆ†æ•°: {quality:.3f}")
#                 print(f"   Topæ–‡æ¡£åˆ†æ•°: {docs[0].get('rerank_score', docs[0].get('score')):.3f}")
#                 print(f"   Topæ–‡æ¡£: {docs[0]['metadata'].get('servant_name')} - {docs[0]['metadata'].get('chunk_type')}")
#             print()
        
#         # è¾“å‡ºå¯¹æ¯”è¡¨æ ¼
#         print("\n" + "="*80)
#         print("é‡æ’åºæ–¹æ³•å¯¹æ¯”ï¼ˆTop 3 æ–‡æ¡£ï¼‰")
#         print("="*80)
        
#         for method, docs in results.items():
#             print(f"\nã€{method.upper()}ã€‘")
#             for i, doc in enumerate(docs[:3], 1):
#                 score = doc.get('rerank_score', doc.get('score', 0))
#                 print(f"  {i}. åˆ†æ•°: {score:.3f} | {doc['metadata'].get('servant_name', 'N/A')} - {doc['metadata'].get('chunk_type', 'N/A')}")
        
#         return True
#     except Exception as e:
#         print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {str(e)}")
#         import traceback
#         traceback.print_exc()
#         return False


# def test_metadata_filter():
#     """æµ‹è¯• 7: å…ƒæ•°æ®è¿‡æ»¤"""
#     print("\n" + "="*60)
#     print("æµ‹è¯• 7: å…ƒæ•°æ®è¿‡æ»¤")
#     print("="*60)
    
#     query = "å®å…·æ•ˆæœ"
    
#     try:
#         # æµ‹è¯•ä¸å¸¦è¿‡æ»¤
#         print(f"ğŸ” æŸ¥è¯¢ï¼ˆæ— è¿‡æ»¤ï¼‰: {query}")
#         docs_no_filter = retrieve_documents(query=query, top_k=3, rerank=False)
#         print(f"   æ£€ç´¢åˆ° {len(docs_no_filter)} ä¸ªæ–‡æ¡£")
#         for doc in docs_no_filter:
#             print(f"   - {doc['metadata'].get('servant_name', 'N/A')}")
        
#         # æµ‹è¯•å¸¦è¿‡æ»¤ï¼ˆå¦‚æœçŸ¥é“æŸä¸ªä»è€…åç§°ï¼‰
#         if docs_no_filter and docs_no_filter[0]['metadata'].get('servant_name'):
#             servant_name = docs_no_filter[0]['metadata']['servant_name']
#             print(f"\nğŸ” æŸ¥è¯¢ï¼ˆè¿‡æ»¤ä»è€…={servant_name}ï¼‰: {query}")
#             docs_filtered = retrieve_documents(
#                 query=query,
#                 top_k=3,
#                 rerank=False,
#                 filter_metadata={"servant_name": servant_name}
#             )
#             print(f"   æ£€ç´¢åˆ° {len(docs_filtered)} ä¸ªæ–‡æ¡£")
#             for doc in docs_filtered:
#                 print(f"   - {doc['metadata'].get('servant_name', 'N/A')} ({doc['metadata'].get('chunk_type', 'N/A')})")
        
#         return True
#     except Exception as e:
#         print(f"âŒ å…ƒæ•°æ®è¿‡æ»¤æµ‹è¯•å¤±è´¥: {str(e)}")
#         import traceback
#         traceback.print_exc()
#         return False


# def run_all_tests():
#     """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
#     print("\n" + "="*60)
#     print("ğŸš€ å¼€å§‹è¿è¡Œ RAG æ¨¡å—æµ‹è¯•")
#     print("="*60)
    
#     tests = [
#         ("å‘é‡æ•°æ®åº“è¿æ¥", test_vectordb_connection),
#         ("åŸºæœ¬æ£€ç´¢", test_basic_retrieval),
#         ("CrossEncoderé‡æ’åº", test_crossencoder_rerank),
#         ("å…³é”®è¯é‡æ’åº", test_keyword_rerank),
#         ("æ£€ç´¢è´¨é‡è¯„ä¼°", test_retrieval_quality),
#         ("å¯¹æ¯”é‡æ’åºæ–¹æ³•", test_compare_rerank_methods),
#         ("å…ƒæ•°æ®è¿‡æ»¤", test_metadata_filter),
#     ]
    
#     results = []
#     for test_name, test_func in tests:
#         try:
#             result = test_func()
#             results.append((test_name, result))
#         except Exception as e:
#             print(f"âŒ æµ‹è¯• '{test_name}' å‘ç”Ÿå¼‚å¸¸: {str(e)}")
#             results.append((test_name, False))
    
#     # è¾“å‡ºæµ‹è¯•æ€»ç»“
#     print("\n" + "="*60)
#     print("ğŸ“Š æµ‹è¯•æ€»ç»“")
#     print("="*60)
    
#     passed = sum(1 for _, result in results if result)
#     total = len(results)
    
#     for test_name, result in results:
#         status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
#         print(f"{status} - {test_name}")
    
#     print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
#     print("="*60)
    
#     return passed == total


# if __name__ == "__main__":
#     success = run_all_tests()
#     sys.exit(0 if success else 1)