# from llm.router import ModelRouter
# import asyncio


# async def test_stream():
#     """æµ‹è¯•æµå¼è¾“å‡º"""
#     print("=" * 50)
#     print("æµ‹è¯•æµå¼è¾“å‡º")
#     print("=" * 50)
    
#     router = ModelRouter(config_path="llm/config.yaml")
#     stream_result = await router.chat(
#         model="fgo-chat-model",
#         messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹è‡ªå·±"}],
#         stream=True,
#     )
    
#     # stream_result ç°åœ¨æ˜¯ StreamWithMetadata å¯¹è±¡
#     print("æµå¼è¾“å‡ºï¼š", end="")
#     async for chunk in stream_result:
#         content = chunk.get("choices", [{}])[0].get("delta", {}).get("content")
#         if content:
#             print(content, end="", flush=True)
    
#     print("\n")
#     # æµå¼ä¼ è¾“å®Œæˆåï¼Œå¯ä»¥è·å–å…ƒæ•°æ®ï¼ˆé€šè¿‡é—­åŒ…å˜é‡ï¼‰
#     if hasattr(stream_result, '_metadata_dict'):
#         instance_name = stream_result._metadata_dict.get('instance_name')
#         physical_model_name = stream_result._metadata_dict.get('physical_model_name')
#         print(f"ä½¿ç”¨çš„å®ä¾‹: {instance_name}")
#         print(f"ç‰©ç†æ¨¡å‹: {physical_model_name}")


# async def test_non_stream():
#     """æµ‹è¯•éæµå¼è¾“å‡º"""
#     print("\n" + "=" * 50)
#     print("æµ‹è¯•éæµå¼è¾“å‡º")
#     print("=" * 50)
    
#     router = ModelRouter(config_path="llm/config.yaml")
#     result, instance_name, physical_model_name, failover_events = await router.chat(
#         model="fgo-chat-model",
#         messages=[{"role": "user", "content": "ä½ å¥½"}],
#         stream=False,
#     )
    
#     # æ‰“å°ç»“æœ
#     content = result.get("choices", [{}])[0].get("message", {}).get("content")
#     print(f"å›å¤: {content}")
#     print(f"ä½¿ç”¨çš„å®ä¾‹: {instance_name}")
#     print(f"ç‰©ç†æ¨¡å‹: {physical_model_name}")
#     print(f"Token ä½¿ç”¨: {result.get('usage', {})}")
#     print(f"å®¹ç¾äº‹ä»¶: {failover_events}")


# async def main():
#     """ä¸»æµ‹è¯•å‡½æ•°"""
#     # æµ‹è¯•æµå¼
#     await test_stream()
    
#     # æµ‹è¯•éæµå¼
#     await test_non_stream()


# if __name__ == "__main__":
#     asyncio.run(main())



# """
# æµ‹è¯• parse.py çš„è¾“å‡ºç»“æ„
# """


# import json
# from data.parse_wiki import parse_full_wikitext

# # è¯»å–ä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶
# with open('data/textarea/é˜¿å°”æ‰˜è‰é›…Â·æ½˜å¾·æ‹‰è´¡.txt', 'r', encoding='utf-8') as f:
#     wikitext_content = f.read()

# # è§£æ
# parsed_data = parse_full_wikitext(wikitext_content)

# # æ‰“å°JSONç»“æ„
# print(json.dumps(parsed_data, indent=2, ensure_ascii=False))

# # æ‰“å°ç»“æ„æ¦‚è§ˆ
# print("\n" + "="*80)
# print("æ•°æ®ç»“æ„æ¦‚è§ˆï¼š")
# print("="*80)
# for key, value in parsed_data.items():
#     if isinstance(value, dict):
#         print(f"\nã€{key}ã€‘ (å­—å…¸)")
#         for k, v in list(value.items())[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
#             print(f"  {k}: {str(v)[:50]}...")
#     elif isinstance(value, list):
#         print(f"\nã€{key}ã€‘ (åˆ—è¡¨, é•¿åº¦: {len(value)})")
#         if value:
#             print(f"  ç¬¬ä¸€é¡¹ç±»å‹: {type(value[0])}")
#             if isinstance(value[0], dict):
#                 print(f"  ç¬¬ä¸€é¡¹çš„é”®: {list(value[0].keys())}")
#     else:
#         print(f"\nã€{key}ã€‘: {str(value)[:50]}")



"""
æµ‹è¯•å‘é‡æ•°æ®åº“è¿æ¥

æµ‹è¯•å†…å®¹ï¼š
1. é…ç½®åŠ è½½
2. è¿æ¥åˆå§‹åŒ–
3. Embedding å‡½æ•°
4. é›†åˆåˆ›å»º
5. æ•°æ®æ’å…¥å’ŒæŸ¥è¯¢
"""

import asyncio

from database.kb.config import get_vectordb_config, update_config
from database.kb.connection import get_vectordb_connection, reset_connection


def test_config():
    """æµ‹è¯•1ï¼šé…ç½®åŠ è½½"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 1: é…ç½®åŠ è½½")
    print("=" * 80)
    
    try:
        config = get_vectordb_config()
        
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   å‘é‡æ•°æ®åº“è·¯å¾„: {config.persist_directory}")
        print(f"   é›†åˆåç§°: {config.collection_name}")
        print(f"   LLM é…ç½®è·¯å¾„: {config.llm_config_path}")
        print(f"   Embedding æ¨¡å‹: {config.embedding_model_name}")
        print(f"   é»˜è®¤æ£€ç´¢æ•°é‡ k: {config.default_k}")
        
        return True
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False


def test_connection_init():
    """æµ‹è¯•2ï¼šè¿æ¥åˆå§‹åŒ–"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: è¿æ¥åˆå§‹åŒ–")
    print("=" * 80)
    
    try:
        connection = get_vectordb_connection()
        
        print(f"âœ… è¿æ¥å¯¹è±¡åˆ›å»ºæˆåŠŸ")
        print(f"   ç±»å‹: {type(connection)}")
        
        # æµ‹è¯•è·å–å®¢æˆ·ç«¯
        client = connection.get_client()
        print(f"âœ… ChromaDB å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"   ç±»å‹: {type(client)}")
        
        # åˆ—å‡ºç°æœ‰é›†åˆ
        collections = connection.list_collections()
        print(f"âœ… ç°æœ‰é›†åˆæ•°é‡: {len(collections)}")
        if collections:
            print(f"   é›†åˆåˆ—è¡¨: {collections}")
        
        return True
    except Exception as e:
        print(f"âŒ è¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_embedding_function():
    """æµ‹è¯•3ï¼šEmbedding å‡½æ•°"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: Embedding å‡½æ•°")
    print("=" * 80)
    
    try:
        connection = get_vectordb_connection()
        
        # è·å– Embedding å‡½æ•°
        print("ğŸ“¦ æ­£åœ¨åˆå§‹åŒ– Embedding å‡½æ•°...")
        embedding_func = connection.get_embedding_function()
        
        print(f"âœ… Embedding å‡½æ•°åˆ›å»ºæˆåŠŸ")
        print(f"   ç±»å‹: {type(embedding_func)}")
        
        # æµ‹è¯•ç¼–ç 
        print("\nğŸ“ æµ‹è¯•æ–‡æœ¬ç¼–ç ...")
        test_texts = [
            "é˜¿å°”æ‰˜è‰é›…Â·æ½˜å¾·æ‹‰è´¡æ˜¯ä¸€ä½SaberèŒé˜¶çš„ä»è€…",
            "æ¢…æ—æ˜¯å¼ºåŠ›çš„è¾…åŠ©å‹Caster"
        ]
        
        print(f"   è¾“å…¥æ–‡æœ¬æ•°é‡: {len(test_texts)}")
        for i, text in enumerate(test_texts, 1):
            print(f"   æ–‡æœ¬{i}: {text[:30]}...")
        
        print("\nğŸ”„ æ­£åœ¨è°ƒç”¨ LLM Router ç”Ÿæˆå‘é‡...")
        vectors = embedding_func(test_texts)
        
        print(f"âœ… å‘é‡ç”ŸæˆæˆåŠŸ!")
        print(f"   è¿”å›å‘é‡æ•°é‡: {len(vectors)}")
        print(f"   å‘é‡ç»´åº¦: {len(vectors[0]) if vectors else 0}")
        print(f"   ç¬¬ä¸€ä¸ªå‘é‡å‰5ç»´: {vectors[0][:5] if vectors else []}")
        
        return True
    except Exception as e:
        print(f"âŒ Embedding å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_collection_operations():
    """æµ‹è¯•4ï¼šé›†åˆæ“ä½œ"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 4: é›†åˆæ“ä½œ")
    print("=" * 80)
    
    try:
        connection = get_vectordb_connection()
        
        # åˆ›å»ºæµ‹è¯•é›†åˆ
        test_collection_name = "test_collection"
        
        print(f"ğŸ“¦ åˆ›å»ºæµ‹è¯•é›†åˆ: {test_collection_name}")
        collection = connection.get_or_create_collection(
            collection_name=test_collection_name,
            metadata={"description": "æµ‹è¯•é›†åˆ"}
        )
        
        print(f"âœ… é›†åˆåˆ›å»ºæˆåŠŸ")
        print(f"   é›†åˆåç§°: {collection.name}")
        print(f"   æ–‡æ¡£æ•°é‡: {collection.count()}")
        
        # æ’å…¥æµ‹è¯•æ•°æ®
        print("\nğŸ“ æ’å…¥æµ‹è¯•æ•°æ®...")
        test_documents = [
            "ä»è€…ï¼šé˜¿å°”æ‰˜è‰é›…Â·æ½˜å¾·æ‹‰è´¡\nç±»å‹ï¼šåŸºç¡€æ•°å€¼\nèŒé˜¶ï¼šSaber",
            "ä»è€…ï¼šæ¢…æ—\nç±»å‹ï¼šä¸»åŠ¨æŠ€èƒ½1\næŠ€èƒ½åï¼šæ¢¦å¹»çš„é­…æƒ‘ A"
        ]
        test_ids = ["test_doc_1", "test_doc_2"]
        test_metadatas = [
            {"servant_name": "é˜¿å°”æ‰˜è‰é›…", "type": "åŸºç¡€æ•°å€¼"},
            {"servant_name": "æ¢…æ—", "type": "æŠ€èƒ½"}
        ]
        
        collection.add(
            documents=test_documents,
            ids=test_ids,
            metadatas=test_metadatas
        )
        
        print(f"âœ… æ•°æ®æ’å…¥æˆåŠŸ")
        print(f"   æ’å…¥æ–‡æ¡£æ•°: {len(test_documents)}")
        print(f"   å½“å‰æ€»æ–‡æ¡£æ•°: {collection.count()}")
        
        # æŸ¥è¯¢æ•°æ®
        print("\nğŸ” æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½...")
        query_text = "é˜¿å°”æ‰˜è‰é›…çš„åŸºç¡€æ•°å€¼"
        
        print(f"   æŸ¥è¯¢æ–‡æœ¬: {query_text}")
        results = collection.query(
            query_texts=[query_text],
            n_results=2
        )
        
        print(f"âœ… æŸ¥è¯¢æˆåŠŸ")
        print(f"   è¿”å›ç»“æœæ•°: {len(results['ids'][0])}")
        for i, (doc_id, document, distance) in enumerate(zip(
            results['ids'][0],
            results['documents'][0],
            results['distances'][0]
        ), 1):
            print(f"\n   ç»“æœ{i}:")
            print(f"     ID: {doc_id}")
            print(f"     è·ç¦»: {distance:.4f}")
            print(f"     æ–‡æ¡£: {document[:50]}...")
        
        # æ¸…ç†æµ‹è¯•é›†åˆ
        print(f"\nğŸ—‘ï¸  æ¸…ç†æµ‹è¯•é›†åˆ...")
        connection.delete_collection(test_collection_name)
        print(f"âœ… æµ‹è¯•é›†åˆå·²åˆ é™¤")
        
        return True
    except Exception as e:
        print(f"âŒ é›†åˆæ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_full_workflow():
    """æµ‹è¯•5ï¼šå®Œæ•´å·¥ä½œæµ"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 5: å®Œæ•´å·¥ä½œæµï¼ˆæ’å…¥ â†’ æ£€ç´¢ â†’ è¿‡æ»¤ï¼‰")
    print("=" * 80)
    
    try:
        connection = get_vectordb_connection()
        
        # åˆ›å»ºæµ‹è¯•é›†åˆ
        test_collection_name = "test_full_workflow"
        collection = connection.get_or_create_collection(test_collection_name)
        
        # æ’å…¥å¤šä¸ªä»è€…æ•°æ®
        print("ğŸ“ æ’å…¥æµ‹è¯•æ•°æ®...")
        documents = [
            "ä»è€…ï¼šé˜¿å°”æ‰˜è‰é›…\nç±»å‹ï¼šå®å…·1\nå®å…·åï¼šèª“çº¦èƒœåˆ©ä¹‹å‰‘\nå¡è‰²ï¼šBuster",
            "ä»è€…ï¼šé˜¿å°”æ‰˜è‰é›…\nç±»å‹ï¼šä¸»åŠ¨æŠ€èƒ½1\næŠ€èƒ½åï¼šç›´æ„Ÿ A\næ•ˆæœï¼šè‡ªèº«è·å¾—æ˜Ÿæ˜Ÿ",
            "ä»è€…ï¼šæ¢…æ—\nç±»å‹ï¼šå®å…·1\nå®å…·åï¼šæ°¸ä¹…é¥è¿œçš„ç†æƒ³ä¹¡\nå¡è‰²ï¼šArts",
            "ä»è€…ï¼šæ¢…æ—\nç±»å‹ï¼šä¸»åŠ¨æŠ€èƒ½1\næŠ€èƒ½åï¼šæ¢¦å¹»çš„é­…æƒ‘ A\næ•ˆæœï¼šè‡ªèº«NPè·å¾—",
            "ä»è€…ï¼šå‰å°”ä¼½ç¾ä»€\nç±»å‹ï¼šå®å…·1\nå®å…·åï¼šå¤©åœ°ä¹–ç¦»å¼€è¾Ÿä¹‹æ˜Ÿ\nå¡è‰²ï¼šBuster"
        ]
        ids = [f"doc_{i}" for i in range(1, 6)]
        metadatas = [
            {"servant_name": "é˜¿å°”æ‰˜è‰é›…", "type": "å®å…·"},
            {"servant_name": "é˜¿å°”æ‰˜è‰é›…", "type": "æŠ€èƒ½"},
            {"servant_name": "æ¢…æ—", "type": "å®å…·"},
            {"servant_name": "æ¢…æ—", "type": "æŠ€èƒ½"},
            {"servant_name": "å‰å°”ä¼½ç¾ä»€", "type": "å®å…·"}
        ]
        
        collection.add(
            documents=documents,
            ids=ids,
            metadatas=metadatas
        )
        print(f"âœ… æ’å…¥ {len(documents)} æ¡æ•°æ®")
        
        # æµ‹è¯•1ï¼šçº¯å‘é‡æœç´¢
        print("\nğŸ” æµ‹è¯•1: çº¯å‘é‡æœç´¢")
        print("   æŸ¥è¯¢: 'Busterå®å…·'")
        results = collection.query(
            query_texts=["Busterå®å…·"],
            n_results=3
        )
        print(f"   è¿”å› {len(results['ids'][0])} ä¸ªç»“æœ:")
        for doc_id, meta in zip(results['ids'][0], results['metadatas'][0]):
            print(f"     {doc_id}: {meta['servant_name']} - {meta['type']}")
        
        # æµ‹è¯•2ï¼šå¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æœç´¢
        print("\nğŸ” æµ‹è¯•2: å…ƒæ•°æ®è¿‡æ»¤æœç´¢")
        print("   æŸ¥è¯¢: 'Busterå®å…·' + where={'servant_name': 'é˜¿å°”æ‰˜è‰é›…'}")
        results = collection.query(
            query_texts=["Busterå®å…·"],
            where={"servant_name": "é˜¿å°”æ‰˜è‰é›…"},
            n_results=3
        )
        print(f"   è¿”å› {len(results['ids'][0])} ä¸ªç»“æœ:")
        for doc_id, meta in zip(results['ids'][0], results['metadatas'][0]):
            print(f"     {doc_id}: {meta['servant_name']} - {meta['type']}")
        
        # æµ‹è¯•3ï¼šç²¾ç¡®IDæŸ¥è¯¢
        print("\nğŸ” æµ‹è¯•3: ç²¾ç¡®IDæŸ¥è¯¢")
        print("   æŸ¥è¯¢ID: ['doc_1', 'doc_3']")
        results = collection.get(
            ids=["doc_1", "doc_3"],
            include=["documents", "metadatas"]
        )
        print(f"   è¿”å› {len(results['ids'])} ä¸ªç»“æœ:")
        for doc_id, meta in zip(results['ids'], results['metadatas']):
            print(f"     {doc_id}: {meta['servant_name']} - {meta['type']}")
        
        # æ¸…ç†
        print(f"\nğŸ—‘ï¸  æ¸…ç†æµ‹è¯•æ•°æ®...")
        connection.delete_collection(test_collection_name)
        
        return True
    except Exception as e:
        print(f"âŒ å®Œæ•´å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€" * 40)
    print(" " * 20 + "å‘é‡æ•°æ®åº“è¿æ¥æµ‹è¯•")
    print("ğŸš€" * 40)
    
    results = []
    
    # è¿è¡Œæµ‹è¯•
    results.append(("é…ç½®åŠ è½½", test_config()))
    results.append(("è¿æ¥åˆå§‹åŒ–", test_connection_init()))
    results.append(("Embeddingå‡½æ•°", test_embedding_function()))
    results.append(("é›†åˆæ“ä½œ", test_collection_operations()))
    results.append(("å®Œæ•´å·¥ä½œæµ", test_full_workflow()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 80)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 80)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}  {test_name}")
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç¯å¢ƒ")
    
    # æ¸…ç†è¿æ¥
    print("\nğŸ”’ æ¸…ç†è¿æ¥...")
    reset_connection()
    print("âœ… è¿æ¥å·²æ¸…ç†")


if __name__ == "__main__":
    main()